# Enhancing Mutual Information Neural Estimation: Theoretical Insights and Practical Applications
ShanghaiTech EE142 final project  
Instructor: Youlong Wu  
Course of Fundamentals of Information Theory, 2024 Fall  
- Addressed numerical challenges in MI estimation, such as instability from logarithmic and exponential
terms, by designing alternative loss functions, including Softplus, Log-Sum-Exp, and regularized loss;
- Applied MINE in enhancing mode coverage in Generative Adversarial Networks, with detailed research on
regularization terms to improve stability and mitigate mode collapse.
